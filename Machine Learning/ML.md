  
Максимальное правдоподобие - выбирать ту гипотезу при которой вероятность имеющихся наблюдений максимальна.  
   
Цель машинного обучения - создавать компьютерные системы, которые адаптируются и обучаются на своем опыте  
Deep Learning - вид машинного обучения, основаный на нейросетях.  
Data Mining - добыча неочевидной информации с большого количества данных.  
DevOps (development и operations) — набор практик, нацеленных на активное взаимодействие и интеграцию специалистов по разработке и специалистов по информационно-технологическому обслуживанию.  
Базируется на идее о тесной взаимозависимости разработки и эксплуатации программного обеспечения, и нацелен на то, чтобы помогать организациям быстрее создавать и обновлять программные продукты и сервисы.  
Business intelligence (сокращённо BI) — это методы и инструменты для перевода необработанной информации в осмысленную, удобную форму. Эти данные используются для бизнес-анализа.  
Технологии BI обрабатывают большие объёмы неструктурированных данных, чтобы найти стратегические возможности для бизнеса.  

Дискре́тность — свойство, противопоставляемое непрерывности, прерывность.  
Дискриминант - это некое число, необходимое для вычисления корней квадратного уравнения  
Дифференцирование - Операция нахождения производной.  
Градиент - вектор, показывающий направление наискорейшего возрастания функции.  
Эмпирический риск (Empirical Risk) — это средняя величина ошибки алгоритма на обучающей выборке.   
Начальное приближения то же, что аппроксимация.  
Аппроксимацией (приближением) функции f(x) называется нахождение такой функции (аппроксимирующей функции) g(x), которая была бы близка заданной. Критерии близости функций могут быть различные.  
Аппроксима́ция или приближе́ние — научный метод, состоящий в замене одних объектов другими, в каком-то смысле близкими к исходным, но более простыми.  
Кусочно-постоянная функция  
Эвристика - отрасль знания, изучающая творческое, неосознанное мышление человека.  
Дихотомия - Последовательное деление целого на две части, затем каждой из них снова на две части и т. д.; ветвление.  
Kafka - реализация очередей  
Storm - движок для стриминга  
Регрессия - отражает зависимость зависимой переменной у от независимых переменных х.  

Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data. You have to turn your inputs into things the algorithm can understand

Feature Extraction -- After generating features, it is often necessary to test transformations of the original features and select a subset of this pool of potential original and derived features for use in your model (i.e. feature extraction and selection). Testing derived values is a common step because the data may contain important information which has a non-linear pattern or relationship with your outcome, thus the importance of the data element may only be apparent in its transformed state (e.g. higher order derivatives). Using too many features can result in multiply colinearity or otherwise confound statistical models, whereas extracting the minimum number of features to suit the purpose of your analysis follows the principal of parsimony.

/-----------------Машинное обучение-----------------------/

Машинное обучение - наука, о том как строить функцию по точкам.  
Восстанавливаем зависимость объектов от ответов.  
X - множество объектов  
Y - множество ответов  
y: X->Y - неизвестная зависимость

Виды машинного обучения:

- С учителем (Есть целевая переменная)  
        - Классификации  
          - Метрическая классификация          
        - Регрессии когда целевая переменная непрерывная (предсказываем цифру от 0 до 100)  
        - Ранжирование — задача сортировки набора элементов из соображения их релевантности по отношению к некому объекту.  
          Алгоритмы: линейные, нелинейные, метрические.  

- без учителя (Нет целевой переменной)  
        - Кластеризация (найти структуру(кластеры) в данных, не знаем что кластеры значат)  
        - Снижение размерности (PCA, t-SNE)  
        - Manifold Learning - С подкреплением  
    
Типы переменных:  
     - Количественные  
     - Номинальные (Категориальные)  
     - Бинарные

С точки зрения задачи:  
     - Features (свободные/предикторные) переменные, используем для предсказания  
     - Target   (целевая) переменная, которую предсказываем

Все обучение состоит из 3 компонент  
LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION  
EVALUATION = An evaluation function (also called objective  
function or scoring function) is needed to distinguish good classifiers from bad ones.

/--------------Регуляризация - задача оптимизации------------/

теорема Гаусса-Маркова  
Если эти 5 условий т.Г-М выполняются, тогда МНК дает оценки максимального правдоподобия(MaxLikelihood) и это объясняет почему мы в оценке ошибки  используем MSE. Поиск весов w с помощью максимизации правдоподобия выборки эквивалентен методу наименьших квадратов.  
1. Признак который моделируем(y) линейно зависит от x. y = wTx+e  
2. Наблюдения (x,y) независимы  
3. Столбцы не должны иметь зависимость(мультиколлинеарность)  
4. E(e|x) = 0 - ошибки независят от x  
5. Гомоскедастичность D(e|x) = сигма^2 - дисперсия ошибки не зависит от координаты  
Гетероскедастичность - дисперсия ошибки зависит от координаты

Т.к. предположения Гаусса-Маркова не всегда выполняются на данных и как следствие линейные модели работают плохо,  
поэтому используют регуляризацию для борьбы с некоторыми нарушениями предположений Г-М.  
Чаще всего регуляризация бореться с мультиколлинеарностью.

Для линейных моделей есть два варианта регуляризации:  
Lasso - L1 - норма = k||w||1 = Сумма модулей весов. Select Operator - обнуляет веса у незначимых признаков т.е. делает Feature Selection. Т.к. по свойству ромба решение сведется в его вершину, где некоторые веса будут имень значение 0.  
Ridge - L2 - норма = k||w||2 = Корень суммы квадратов весов. w1**2 + w2**2 = R**2 уравнение окружности, совместим окружность и график GD сверху. Получится разрешенные веса находятся в этой окружности. Борется с мультиколлинеарностью

Регуляризация - ограничивает веса, если будут большие веса, то плохая интерпретируемость, нестабильность ответов

В задачах регрессии наиболее типичным функцией потерь является квадратичная(SE) функция потерь (y - y_pred)**  
Регуляризация представляет собой приставку к функции потерь

Условная оптимизация т.е. задается условие/ограничение  
SE -> min - оптимизируем  
||w|| меньше C - ограничение

Безусловная оптимизация  
SE + L1 or L2 -> min  
Loss = SE  
R = k*w  
Objective = Loss + R  
The objective function is a means to maximize (or minimize) something.  
Elasticnet = L1+L

w - вес задает число гипотез(моделей), т.е. при разных весах получаются разные ответы(модели)  
Множество гипотез это пространство всех моделей  
С помощбю принципа максимального правдоподобия мы должны выбрать одну гипотезу(модель)  
Максимизируем вероятность наблюдения Y при фиксированных X  
Из метода максимального правдоподобия выводим МНК используя еще одно предположение 6. e ~ N(0, сигма^2) ошибка случайная величина  
Максимизируем логарифм правдоподобия LnL и это равносильно минимизации МНК

Ln(a*b) = Ln(a)+Ln(b)

MSE -> min. Минимизируем MSE используя алгоритм оптимизации Градиентный спуск  
Регуляризатор влият на сложность модели

/--------------------АЛГОРИТМЫ-------------------/  
/-------Линейные методы классификации-------/

Сигналы суммируются и умножаются на постоянные значения (веса). Это линейное преобразование.

Обучение регрессии - это оптимизация  
Модель регресии - линейная, взвешенная сумма всех признаков.

Непрерывная аппроксимация пороговой функции потерь - часто используется в теории классификации, позволяет использовать градиентную оптимизацию, также хороша тем,  
что мы штрафуем объекты за приближение объектов в границе классов.

Проблемы переобучения:  
 Линейная зависимость мультиколлинеарности признаков  
 Слишком мало или много признаков  
   
Плюсы линейных моделей:  
 - Интерпретируемость

Решение проблемы переобучения - регуляризация (сокращение весов)  
Запрещено принимать большие значения

Margin - Если отступ близок к нулю, надежность классификации этого объекта невысока

Хороший линейный классификатор должен минимизировать эмпирический риск — то есть число ошибок на обучающей выборке.  

Минимизация эмпирического риска — очень сложная оптимизационная задача, поэтому он заменяется на другой функционал.  

Как и в случае с метрическими методами, качество линейных алгоритмов зависит от некоторых свойств данных.  
В частности, признаки должны быть нормализованы, то есть иметь одинаковый масштаб.  
Если это не так, и масштаб одного признака сильно превосходит масштаб других, то качество может резко упасть.

Одна из причин популярности линейных методов заключается в том, что они хорошо работают на разреженных данных.

/--------------------Парная Линейная регрессия-------------------/  
Парная регрессия, когда присутствует один признак f(x) = w0 + w1x.

Линейная регрессия — метод восстановления зависимости между двумя переменными.  
Задача регресии - построить функцию, которая предсказывает целевую переменную. f(x) = ax + b;  

y = b0 + b1 * X  
Y - независимая переменная  
x - зависимая переменная  
Уравнение прямой, задается 2 параметрами b0 b1, подбирая эти параметры можно построить линию через точки  
b0 - свободный член(intercept), показывает где линия пересекает ось y.  
b1 - slope отвечает за направление и угол наклона линии.

МНК это метод реализации линейной регрессии. Можно реализовать используюя Градиентный Спуск  
Чтобы сумма квадратов ошибок была минимальна, нужно подобрать intercept(b0) и slope(b1)

Формула для расчет коэффициентов прямой, полученная из МНК. МНК это просто вывод формулы.  
w1 = sum( (Xi - X_m)*(Yi - Y_m) ) / sum(Xi - X_m)**2 = np.cov(x,y) / x.var()  
w0 = Y_mean - w1 * X_mean

x.var() # дисперсия(variance/dispersion)

Если коэффициент корреляции между двумя переменными равен нулю, и обе переменные представлены в z - значениях,  
то уравнение регрессии примет вид y = 0, Если rxy = 0, то b1 = 0, тогда Y = b

1.Строим scatter plot смотрим линейно ли распределение переменных.  
2.Строим распределение остатков. и смотрим нормально ли распределение этих остатков, ведут ли остатки одинаково на всем протяжении

условия применения линейной регрессии  
1. Линейная взаимосвязь X и Y  
2. Нормальное распределение остатков.    
3. Гомоскедастичность  - это одинаковая изменчивость зависимой переменной на всех уровнях независимой переменной (постоянная изменчивость остатков)

Градиентный спуск для обучения линейной регрессии:

/------------------Логистическая регрессия--------------/

Логистическая регрессия — один из видов линейных классификаторов применяется для предсказания вероятности возникновения некоторого события по значениям множества признаков тогда как большинство линейных классификаторов могут выдавать только номера классов. . Для этого вводится зависимая переменная Y, принимающая лишь одно из двух значений, это числа 0 (событие не произошло) и 1 (событие произошло), и множество независимых переменные(также называемых признаками, предикторами или регрессорами)X.  

Используется логарифмическая функция потерь

Логистическую регрессию можно обучать с помощью среднеквадратической ошибки, градиентного спуска.

Метод построения линейных классификаторов.  
Линейная модель классификации - это скалярное произведение вектора объектов на вектор весов.

Принцип максимума правдоподобия - нахождение параметров, при которых появление данной выборки наиболее вероятно.  
Настройка логистической регрессии эквивалентна максимизации правдоподобия ответов классификатора.  
Вероятность принадлежности объекта к положительному классу оценивается как сигмоида от скалярного произведения весов на признаки.

Линейные методы могут переобучаться и давать плохое качество из-за различных проблем в данных: мультиколлинеарности, зашумленности и т.д.  
Чтобы избежать этого, следует использовать регуляризацию — она позволяет понизить сложность модели и не допустить переобучения.  
Сила регуляризации определяется коэффициентом C.  

Регуляризованная логистическая регрессия  
L2 - помогает решать проблему мультиколлинеарности (сокращает веса линейно зависимых признаков), сводится к добавке суммы квадратов весовых коэффициентов  
L1 - вместо квадратов использует модули и имеет эффект отбора признаков (обнуляет веса неинформативных признаков)

Разница между SVM и LogisticRegression - в способе аппроксимации функции потерь в SVM используется кусочно-линейная функция, а лог.регрессии логарифмическая функция потерь LogLoss.

Сигмо́ида — это гладкая монотонная нелинейная функция, имеющая форму буквы "S", которая часто применяется для «сглаживания» значений некоторой величины. Возрастающая функция.  
Часто под сигмоидой понимают логистическую функцию  

Линейный классификатор сначало вычисляет скалярное произведение между вектором признака(x) и вектором весов(w), затем он сравнивает с нулем. Если больше нуля, то это первый класс.  
a(x) = [{w,x}>0]

/------------------------Многомерная линейная регрессия---------------------------/

Многомерная линейная регрессия - решает задачу регресии.

y = w0 + w1*x + w2*x + wn*x

Имеется множество объектов X и множество ответов Y. Также имеется набор n вещественнозначных признаков f_j(x), \ j=1, \ \ldots , \ n. Введём матричные обозначения: матрицу информации F, целевой вектор y, вектор параметров \alpha и диагональную матрицу весов:

Многомерная линейная регрессия называется так из-за того, что вычисляет прогноз как линейную комбинацию многих признаков.  
В двумерном случае обученная модель представляет собой гиперплоскость.  
Многомерная линейная регрессия — это линейная регрессия в n-мерном пространстве (объекты и признаки являются n-мерными векторами).  

Если имеются сингулярные числа, близкие к нулю, то это говорит о том что признаки линейно зависимы (мультиколлинеарны) это приводит к переобучению.  
Задача многомерной регрессии может быть решена через SVD.

Методы устранения мультиколлинеарности: гребневая регрессия, метод главных компонент(PCA).

Гребневая регрессия и метод LASSO - техники регуляризации, которые применяются в линейных моделях.  
Гребневая регрессия - Минимизируем сумму квадратов коэффициентов.  
Метод LASSO(least absolute shrinkage and selection operator) - Минимизируем сумму модулей коэффициентов. Приводит к отбору признаков в линейных моделях. Умеет обнулять коэффициенты неинформативных признаков.

/--------------------Полиномиальная регрессия Линейная регрессия-------------------/

Помогает восстановить нелинейную зависимость к примеру проблема XOR  
для этого наряду с признаками x1, x2, ...,xn - добавляем квадраты или кубы этих признаков.

/------------------Метод опорных векторов (Support Vector Machine, SVM)--------------/

Особым свойством метода опорных векторов является непрерывное уменьшение эмпирической ошибки классификации и увеличение зазора, поэтому метод также известен как метод классификатора с максимальным зазором.

один из видов линейных классификаторов. Функционал, который он оптимизирует, направлен на максимизацию ширины разделяющей полосы между классами. Из теории статистического обучения известно, что эта ширина тесно связана с обобщающей способностью алгоритма, а ее максимизация позволяет бороться с переобучением.

Одна из причин популярности линейных методов заключается в том, что они хорошо работают на разреженных данных. Так называются выборки с большим количеством признаков, где на каждом объекте большинство признаков равны нулю. Разреженные данные возникают, например, при работе с текстами. Дело в том, что текст удобно кодировать с помощью "мешка слов" — формируется столько признаков, сколько всего уникальных слов встречается в текстах, и значение каждого признака равно числу вхождений в документ соответствующего слова. Ясно, что общее число различных слов в наборе текстов может достигать десятков тысяч, и при этом лишь небольшая их часть будет встречаться в одном конкретном тексте.  

Метод опорных векторов имеет еще одну особенность. Если преобразовать его оптимизационную задачу, то окажется, что итоговый классификатор можно представить как взвешенную сумму скалярных произведений данного объекта на объекты обучающей выборки:

По сути, алгоритм делает предсказания на основе сходства нового объекта с объектами обучающей выборки. При этом, как правило, далеко не все коэффициенты оказываются ненулевыми. Это означает, что классификация делается на основе сходства лишь с частью обучающих объектов. Такие объекты называются опорными.

Обучите классификатор с линейным ядром, параметром C = 100000 и random_state=241. Такое значение параметра нужно использовать, чтобы убедиться, что SVM работает с выборкой как с линейно разделимой. При более низких значениях параметра алгоритм будет настраиваться с учетом слагаемого в функционале, штрафующего за маленькие отступы, из-за чего результат может не совпасть с решением классической задачи SVM для линейно разделимой выборки.

предсказание зависит лишь от части объектов

Почему для метода опорных векторов возможно нелинейное обобщение?  
Задачу метода опорных векторов можно переписать так, что она будет зависеть только от скалярных произведений объектов. Эти скалярные произведения можно заменить на функцию, вычисляющую скалярное произведение в пространстве более высокой размерности.

Метод опорных векторов максимизирует отступы объектов, что тесно связано с минимизацией вероятности переобучения.  
При этом он позволяет очень легко перейти к построению нелинейной разделяющей поверхности благодаря ядровому переходу.

Функция потерь - кусочная

Особенность SVM по сравнению с другими линейными классификаторами - использование кусочно-линейной аппроксимации функции потерь и квадратичного регулязатора.

Аппроксимация штрафует объекты за приближение к границе классов, увеличивая зазор между классами.  
Регуляризация - штрафует неустйочивые решения в случае мультиколлинеарности. Помогает избежать переобучение в случае мультиколлинеарности.

SVM для нелинейного случая.  
Самое важное свойство метода является возможность обобщения линейного классификатора на нелинейный случай  
Проблема линейных классификаторов: данные не всегда линейно разделяемы!  
Решение: добавить 'ядра в пространстве данных, получиться линейная классификация в расширенном пространстве

Ядра в SVM нужны, чтобы:  
 - Лучше описывать сложные процессы в закономерности данных, позволяют строить более сложные разделяющие поверхности.  
 - Без ядер не построить нелинейную разделяющую поверхность т.к. SVM является линейным алгоритмом.  
   
 Типы ядер:  
 - Линейное  
 - RBF  
   
 Константа С  
   
 Преимущества/Недостатки  
 + Выделяется множество опорных векторов.  
 + Есть обобщение для нелинейных классификаторов  
 + Есть эффективные численные методы  
 - Опорными объектами могут становиться выбросы  
 - Нужно подбирать Константу С

/---Support Vector Machine---/  
For classification and regression

Pros:  
        It works really well with clear margin of separation  
        It is effective in high dimensional spaces.  
        It is effective in cases where number of dimensions is greater than the number of samples.  
        It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.  
    Cons:  
        It doesn’t perform well, when we have large data set because the required training time is higher  
        It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping  
        SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is related SVC method of Python scikit-learn library.  

/---Naive Bayes algorithm---/  
classification technique based on Bayes’ Theorem  

P(c|x) is the posterior probability of class (c, target) given predictor (x, attributes).  
P(c) is the prior probability of class.  
P(x|c) is the likelihood which is the probability of predictor given class.  
P(x) is the prior probability of predictor.

Pros:

- It is easy and fast to predict class of test data set  
- need less training data than logistic regression  
- It perform well in case of categorical input variables

Cons:

- If categorical variable has a category (in test data set), which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. This is often known as “Zero Frequency”. To solve this, we can use the smoothing technique. One of the simplest smoothing techniques is called Laplace estimation.  
- Another limitation of Naive Bayes is the assumption of independent predictors. In real life, it is almost impossible that we get a set of predictors which are completely independent.  

Методы настройки/оптимизации моделей(минимизация/максимизация функций)

  Гиперпараметр модели - это параметр, который мы передаем модели, тот параметр, который модель не может выучить (к прим. глубина дерева, которую мы задаем изначально)  
Параметр модели - это параметры, которые модель определяет сама.

Настройка модели алгоритмов по данным — это задача оптимизации, от эффективности решения которой зависит практическая применимость метода машинного обучения.  
    
- Метод наименьших квадратов;  
- Методы линейного поиска и доверительной области;  
- Метод градиентного спуска;  
- Метод Ньютона;  
- Метод сопряженных градиентов для решения систем линейных уравнений;  
- Метод сопряженных градиентов для оптимизации неквадратичных функций;  
- Неточный (безгессианный) метод Ньютона применяется для обучения линейного классификатора и нелинейной регрессии;  
- Квазиньютоновские методы оптимизации: DFP, BFGS и L-BFGS;  

/------------------Метод наименьших квадратов (least square method)--------------/

МНК выступает в роли метода для реализации линейной регрессии.  
Чаще всего задача регрессии представляется в виде задачи подгонки прямой линии, проходящей через множество точек.  
Есть несколько вариантов ее осуществления, и метод наименьших квадратов — один из них.  
Можно нарисовать линию, а затем измерить расстояние по вертикали от каждой точки к линии и «перенести» эту сумму вверх. Необходимой линией будет та конструкция, где сумма расстояний будет минимальной.  
Чтобы сумма квадратов ошибок была минимальна, нужно подобрать intercept(b0) и slope(b1)  

Формула для расчет коэффициентов прямой, полученная из МНК.  
МНК это просто вывод формулы.  
w1 = sum( (Xi - X_mean)*(Yi - Y_mean) ) / sum(Xi - X_mean)**2 = np.cov(x,y) / x.var()  
w0 = Y_mean - w1 * X_mean

Смысл метода - найти такие параметры прямой, что остаточная сумма квадратов (Residual sum of squares) была минимальна

/---Полный градиентный спуск (GD) и Стохастический градиентный спуск (SGD) и средний стохастический градиент(SAD)------/

Градиент(∇ƒ) - вектор, показывающий направление наискорейшего возрастания функции, а антиградиент(-∇ƒ) направление наискорейшего убывания.  
Это ключевое свойство градиента, обосновывающее его использование в методах оптимизации.  

Фиксируется начальное приближение для искомого вектора весов.  
Делается последовательность градиентных шагов по антиградиенту, чтобы найти минимум функционала.  
Одна итерация стохастического градиента зависит только от одного объекта - можно считывать их с диска по одному, или же брать из некоторого потока. Подходит для обучения на больших данных.

Оценить градиент суммы функций можно градиентом одного случайного взятого слагаемого. В этом случае мы получим метод стохастического градиентного спуска.  
Таким образом метод стохастического градинта имеет менее трудоемкие итерации по сравнению с полным градиентом, но скорость сходимости у него существенно меньше.

SAD - сочетает в себе низкую сложность итераций стохастичечкого градиентного спуска(SGD) и высокую скорость сходимости полного градиентного спуска(GD).

Выбор длины шага в GD - длину шага уменьшают пропорционально порядковому номеру шага

Достоинства:  
 Легко реализуется  
 Применим к любым моделям и функциям потерь  
 Допускает онлайн(потоковое) обучение  
 На больших выборках позволяет получать хорошие решения, даже не обработав все вектора  
 Чаще применяется в Big Data  
   
Недостатки  
 Возможна расходимость или медленная сходимость  
 Переобучение из мультиколлиниарности  
   
Данный метод требует доработки для улучшения сходимости и получения лучшего решения.  
Регуляризация решает проблему мультиколлинеарности и снижает риск переобучения.  
   
Сначала задаем Loss Function  
Затем Objective Function тут присутствует переменная с весами  
/--------------Loss Functions (Функции потерь)--------------/

/--Loss functions for classification--/  
Hinge Loss  
Square Loss - used in regression  
Logistic Loss  
Cross Entropy Loss

E(M) - функции потерь.  
Функция отступа - Mi = b(xi)*yi - Произведение композиции b(xi) на ответы y.

E(M) = e^-M - экспоненциальная (AdaBoost);  
L(M) = log2(1+e^-M) - логарифмическая (LogitBoost);  
G(M) = exp(-cM(M+s)) - гауссовская (BrownBoost); не штрафует за шумы, выбросы  
Q(M) = (1-M)**2 - квадратичная;  
S(M) = 2(1+e**M)**-1 - сигмоидная;  
V(M) = (1-M)+ - кусочно-линейная (SVM);

/------------------------------/  
maximize the posterior probabilities (e.g., naive Bayes)  
maximize a fitness function (genetic programming)  
maximize the total reward/value function (reinforcement learning)  
maximize information gain/minimize child node impurities (CART decision tree classification)  
minimize a mean squared error cost (or loss) function (CART, decision tree regression, linear regression, adaptive linear neurons)  
maximize log-likelihood or minimize cross-entropy loss (or cost) function  
minimize hinge loss (support vector machine)

/--------------------Метрические методы классификации-------------------/

Метрический классификатор (similarity-based classifier) — алгоритм классификации, основанный на вычислении оценок сходства между объектами.  
Простейшим метрическим классификатором является метод ближайших соседей, в котором классифицируемый объект относится к тому классу, которому принадлежит большинство схожих с ним объектов. Определяются функцией расстояния.  

Главным параметром любого метрического алгоритма является функция расстояния, используемая для измерения сходства между объектами.

Метрические методы основаны на гипотезе компактности  
Гипотеза Компактности - близки объекты лежат в одном классе.

Метрические методы чувствительны к масштабу признаков — так, если масштаб одного из признаков существенно превосходит масштабы остальных признаков,  
то их значения практически не будут влиять на ответы алгоритма. Поэтому важно производить масштабирование признаков. Обычно это делается путем вычитания среднего значения признака и деления на стандартное отклонение.  
В противном случае признак с наибольшими числовыми значениями будет доминировать в метрике, остальные признаки, фактически, учитываться не будут.  
Однако и нормировка является весьма сомнительной эвристикой, так как остаётся вопрос: «неужели все признаки одинаково значимы и должны учитываться примерно с одинаковым весом?»  
Если признаков слишком много, а расстояние вычисляется как сумма отклонений по отдельным признакам, то возникает проблема проклятия размерности. Суммы большого числа отклонений с большой вероятностью имеют очень близкие значения (согласно закону больших чисел). Получается, что в пространстве высокой размерности все объекты примерно одинаково далеки друг от друга; в частности, выбор k ближайших соседей становится практически случайным.  
Проблема решается путём отбора относительно небольшого числа информативных признаков (features selection). В алгоритмах вычисления оценок строится множество различных наборов признаков (т.н. опорных множеств), для каждого строится своя функция близости, затем по всем функциям близости производится голосование.  

Разновидности метрических алгоритмов   
   
- Метод ближайших соседей  
- Метод потенциальных функций  
- Метод радиальных базисных функций  
- Метод парзеновского окна  
- Метод дробящихся эталонов  
- Алгоритм вычисления оценок

/------------------Метод ближайших соседей KNN----------------------/

процесс обучения алгоритма k ближайших соседей - Запоминание всех объектов обучающей выборки  
Метод использующий функции расстояния в пространстве объектов.

Редакторское расстояние Левенштейна.  
Метод окна Парзена - помогает уменьшать вес соседей, которые находятся дальше. Есть методы фиксированной и переменной ширины. h  
Метод Потенциальных функций - разновидность линейного классификатора. В качестве признаков используем функцию близости.

Формула Надарая-Ватсона - В методе KNN ответы предполагаются дискретными, его нельзя использовать для решения задач регрессии, а Формула Надарая-Ватсона как раз используется для регрессии.  
Соотношение формулы Надарая-Ватсона и метод KNN - оба метода агрегируют ответы на объектах обучающей выборки с некоторыми весами. Если в методе KNN использовать окна Парзена, то формула похожа на формулу Надарая-Ватсона.  
Формула Надарая-Ватсона - усредняет ответы всех объектов обучающей выборки с весами, обратно пропорциональными расстоянию до них.

/------------------Решающие деревья (метод разбиений/ДЕРЕВО РЕШЕНИЙ)--------------/

Параметры Решающего Дерева в sklearn  
criterion - критерий ветвления gini or entropy.  
splitter -  
max_depth - ограничивают глубину дерева.  
max_features - количество фичей передаваемые в модель для поиска лучшего разбиения.  
min_samples_split - минимальное кол-во значений в узле при котором еще происходит деление узла на листья.  
min_samples_leaf - минимальное кол-во значений, который должны быть в листе.  
max_leaf_nodes - максимальное возможное кол-во листьев.  
min_impurity_split - задает порог разделения. Если примесь узла выше порога он будет разделяться

Деревья состоят:  
- Узлы(вершины) - содержат условие, по одной переменной и они бинарны.  
- Ветки(грани) - True/False.  
- Листья(вершины) - константы, если задача регрессии, то число, если классификации, то метка, класс. Решение находится в листах.  
   
Алгоритмы построения решающих деревьев:  
- ID3 (Induction of Desicion Trees):  
Оптимизация ID3: pruning (усечение дерева) реализовано в алгоритме С4.5 - помогает решить проблему алгоритма ID3, который переусложняет структуру дерева.Pruning работает после того, как построено все дерево алгоритмом ID3.  
- CART (Classification and Regression Tree) критерий информативномсти - MSE(среднеквадратическая ошибка)  
Оптимизация CART: критерий Minimal Cost-Complexity Pruning, леса решений

Критерия ветвления, критерий информативности в задачах классификации:  
- Критерий Джини - подсчитывает число пар объектов лежащих в одном классе, которые вместе идут в одну из дочерних вершин. У этих объектов должны совпадать метки классов и значение предиката.  
- Ошибка классификации  
- Энтропийный критерий - Entropy, Information Gain  
На практике ошибка классификации почти не используется, а неопределенность Джини и прирост информации работают почти одинаково.

Критерий ветвления в задаче регрессии:  
- Дисперсионный критерий

Достоинства/Недостатки  
+ Хорошо и эффективно обходят пропуски в данных.  
+ Допустимы разнотипные данные и данные с пропусками  
+ Хорошо интерпретируется человеком  
+ Не надо думать над метрикой и параметрами  
+ Устойчив к изменениям признаков  
+ Хорошо распаралелливается (т.к. деревья строятся независимо друг от друга, можно запускать их параллельно)  
+ Не переобучается при увеличении количества деревьев

- Жадный алгоритм ID3 - переусложняет структуру дерева.  
- Высокая чувствительность к шуму, к составу выборки.  
- Плохо приближает линейные зависимости.  
- Долго строится и используется (т.к. деревья большой глубины).  
- Нехорошо работают на выборках с большим количеством признаков.

При увеличении глубины решающего дерева возрастает риск переобучиться.  
max_depth - в модели ограничивают глубину дерева

Разница между решающим деревом глубиной 100 и 100 решащих пней в том, что дерево дробит одну область(точку), а пень дробит все пространство точек.

Случайный лес - у нас есть 1000 пациентов. делаем случайную выборку в 800 пациентов - обучаем дерево, далее берем еще 800 пациентов обучаем еще одно дерево и так делаем 1000 деревьев, а потом эти 1000 деревьев усредняем.

Для построения алгоритма решающего дерева используется энтропия и Information Gain, лежит принцип жадной максимизации прироста информации – на каждом шаге выбирается тот признак, при разделении по которому прирост информации оказывается наибольшим.  
Дальше процедура повторяется рекурсивно, пока энтропия не окажется равной нулю или какой-то малой величине (если дерево не подгоняется идеально под обучающую выборку во избежание переобучения).В разных алгоритмах применяются разные эвристики для "ранней остановки" или "отсечения", чтобы избежать построения переобученного дерева.  

Feature Interaction - сколько факторов могут взаимодействовать между собой для получения результата.

/------------------------Метрики качества---------------------------/  
   
В задачах классификации может быть много особенностей, влияющих на подсчет качества: различные цены ошибок, несбалансированность классов и т.д.  
Из-за этого существует большое количество метрик качества — каждая из них рассчитана на определенное сочетание свойств задачи и требований к ее решению.  
   
Меры качества классификации можно разбить на две большие группы: предназначенные для алгоритмов, выдающих номера классов, и для алгоритмов, выдающих оценки принадлежности к классам.  
К первой группе относятся доля правильных ответов, точность, полнота, F-мера.  
Ко второй — площади под ROC- или PR-кривой.  

___________y = 1___y = 0__  
|a(x) = 1 |  TP   |   FP   |  
|--------------------------  
|a(X) = 0 |  FN   |   TN   |  
 --------------------------  
   
True Positive - верные срабатывание  
False Positive - ложное срабатывание  
False Negative - ложный пропуск  
True Negative - верный пропуск

1. Accuracy (доля правильных ответов) - на скольких объектах мы даем правильный ответ и поделить на размер выборки.  
 - Плохо работает на несбалансированных данных. Допустим есть 950 объектов с классом 1 и 50 объектов с классом 0. Мы вернем для всех объектов класс 0 и у нас получится точность 95%. Это плохо.  
 - Разные ошибки имеют разную цену.

2. Precision Recall (Точность и полнота) - две метрики, которые используются вместе и работают на несбалансированных данных.  
Precision - насколько мы можем доверять классификатору = TP / TP + FP. Чем выше точность, тем меньше ложных срабатываний.  
Recall - как много объектов класса 1 находит наш классификатор = TP / TP + FN. Чем выше полнота, тем меньше ложных пропусков.

Т.к. у нас метрики Precision Recall, а хочется работать с одной поэтому делаем Гармоническое среднее или F-мера: F = 2 * Precision * Recall / Precision + Recall

Пример: есть 5 объектов принадлежащих классу 1 и 5 объектов принадлежащих классу 0. Наших классификатор отнес 3 объекта из 1 класса к 1 классу и 2 объекта из 1 класса к 0 классу

___________y = 1___y = 0__  
|a(x) = 1 |   3   |   0    |  
|--------------------------  
|a(X) = 0 |   2   |   5    |  
 --------------------------  
   
По формуле Precision = TP / TP + FP = 100 %  
По формуле Recall = TP / TP + FN = 60 %

TP(1) — это количество объектов, имеющих класс 1, отнесенных алгоритмом к классу 1.  
TN(4) — это количество объектов, имеющих класс 0, отнесенных алгоритмом к классу 0.  

FP(2) — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1.  
FN(3) — это количество объектов, имеющих класс 1, отнесенных алгоритмом к классу 0.  

Еще примеры:

- Определение мошеннических действий на счетах  
   Важнее полнота, чем точность. Мы лишний раз проверим не мошенническую операцию, но зато не пропустим мошенническую.  
- Определение вражеских самолетов для автоматического уничтожения  
   Важнее точность, нельзя допустить стрельбы по своим.  
    
 PR - кривая основана на двух показателях: Precision и Recall. Работает лучше, чем ROC в сильно несбалансированных классах.  
- Нужно отсортировать объекты по возрастанию оценки.  
- Перебираем все пороги классификации, начиная с максимального.  
- Для каждого порога считаем точность и полноту.  
- Нанесем соответствующую точку в осях точность и полнота.  
- Соединим точки, получим PR-кривую.

ROC - кривая основана на двух показателях: доля верных и доля ложных срабатываний. ROC-кривая строится в осях "доля ошибочных положительных классификаций" и "доля верных положительных классификаций"  
- по оси X: False Positive Rate, ошибочно положительные объекты. FPR = FP / FP + TN  
- по оси Y: True Positive Rate, число верных срабатываний. TPR = TP / TP + FN  
Левая точка кривой всегда в точке (0,0)  
Правая точка кривой всегда в точке (1,1)

ROC, AUC and Gini  
дисбаланс классов – не помеха для ROC AUC, за это метрику и любят  
/----Gini coefficient----/  

Another method to measure the performance in binary classification beside accurary is the ROC method.  
ROC AUC is the Area Under ROC Curve  
ROC - график классификаотра с threshold'ом, используется для оценки производительности модели классификатора.

ROC AUC - просто площадь под кривой. Range [0:1]  
Gini = 2*AUC-1. Range [-1:1]

Gini - используют при оценке качества классификации и регрессии, чем выше Gini, тем больше доверия этому графику.  
Gini coefficient is related to ROC (Receiver Operating Characteristic)  
ROC to ROC is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied, while  
ROC представляет собой графический график, который иллюстрирует работу системы двоичного классификатора, поскольку порог ее дискриминации варьируется

В двоичной классификации часто качество модели рассчитывается термином Accuracy(Точность). TP+TN / P+N(all data)

[https://staesthetic.wordpress.com/2014/04/14/gini-roc-auc-and-accuracy/](https://staesthetic.wordpress.com/2014/04/14/gini-roc-auc-and-accuracy/)

[http://www.business-insight.com/blog/2016/07/lift-roc-auc-and-gini/](http://www.business-insight.com/blog/2016/07/lift-roc-auc-and-gini/)

[https://alexanderdyakonov.wordpress.com/2015/12/15/%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%BC%D1%8C%D1%82%D0%B5%D1%81%D1%8C-%D0%B4%D0%B6%D0%B8%D0%BD%D0%B8/](https://alexanderdyakonov.wordpress.com/2015/12/15/%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%BC%D1%8C%D1%82%D0%B5%D1%81%D1%8C-%D0%B4%D0%B6%D0%B8%D0%BD%D0%B8/)

[https://www.kaggle.com/wiki/Gini](https://www.kaggle.com/wiki/Gini)

Коэффициент Джини - всего лишь шкала прогностической мощности от 0 до 1. Высший Джини означает большую прогностическую силу, более низкий уровень Джини означает меньшую прогностическую силуr

Коэффициент Джини наиболее широко используется экономистами в качестве показателя статистической дисперсии, предназначенной для представления распределения доходов жителей страны. Это наиболее часто используемая мера неравенства.

Другое использование для коэффициентов Джини заключается в оценке прогностической способности моделей кредитного скоринга. Хотя вычисление Джини для кредитора довольно сложно, понимание Джини несколько проще.

Коэффициент Джини может помочь кредитору (или инвестору) понять, насколько хороша кредитная модель кредитора при прогнозировании того, кто будет погашать и кто будет дефолтен по кредиту.  
Коэффициент GINI сравнивает кривую «Лоренца» (кумулятивное распределение) с линией совершенной случайности. Графически проиллюстрированный, Gini - это отношение площади под кривой (A), но выше линии совершенной случайности во всю область над линией совершенной случайности (A + B). См. Рисунок ниже.

В 1 батче среди недефолтных клиентов оказалось 11.71% дефолтных клиентов , которых модель смогла определить  
В 10 батче среди недефолтных клиентов оказалось 1.32% дефолтных клиентов , которых модель смогла определить

/------------------------Мультиклассовая классификация---------------------------/

Мультиклассовая классификация можно свести к серии бинарных задач, есть два подхода:

One-vs-all:

- Линейное число классификаторов, но каждый обучается на полной выборке.  
 - Возникают проблемы с несбалансированными выборками.

All-vs-all:

- Квадратичное число классификаторов, но каждый обучается на небольшой подвыборке.  
   
 /------------------------Композиции алгоритмов---------------------------/  
   
 Построение композиции — важный подход в машинном обучении, который позволяет объединять большое количество слабых алгоритмов в один сильный.  
 Объединение большого числа моделей в композицию может значительно улучшить итоговое качество за счет того, что отдельные модели будут исправлять ошибки друг друга.  

Прикомпозиции базовые классификаторы должны быть различными:  
 - Обчение по случайным выборкам  
 - Обучение по выборке со случайными весами объектов  
 - Обучение по случайным подмножествам признаков  
 - Различные начальные приближения  
 - Различные модели классификации  
   
 Бэггинг (bagging, bootstrap aggregation) - метод построения композиций, использует простое голосование  
 Бустинг - метод построения композиций, использует взвешенное голосование, где каждый алгоритм получает весовой коэффициент. Последовательное построение базовых алгоритмов.  
   
 Метод случайных подпространств (RSM, random subspace method) - b(x) обучаются по случайным подмножествам n признаков.  
   
Бустинг  
Бэггинг  
Блендинг (Blending)  
Cтекинг (Stacking)

Бустинг (от англ. boosting – усиление) называется метод, направленный на превращение слабых моделей в сильные путем построения ансамбля классификаторов.  
При бустинге происходит последовательное обучение классификаторов. Таким образом, обучающий набор данных на каждом последующем шаге зависит от точности прогнозирования предыдущего базового классификатора. Первый алгоритм Boost1, например, применял три базовых классификатора. При этом первый классификатор обучался на всем наборе данных, второй на выборке примеров, а третий – на наборе тех данных, где результаты прогнозирования первых двух классификаторов разошлись. Современная модификация первого алгоритма подразумевает использование неограниченного количества классификаторов, каждый из которых обучается на одном наборе примеров, поочередно применяя их на различных шагах.  

Бэггинг (bootstrap aggregating) использует параллельное обучение базовых классификаторов (говоря языком математической логики, бэггинг – улучшающее объединение, а бустинг – улучшающее пересечение). В ходе бэггинга происходит следующее:  
Из множества исходных данных случайным образом отбирается несколько подмножеств, содержащих количество примеров, соответствующее количеству примеров исходного множества.  
Поскольку отбор осуществляется случайным образом, то набор примеров всегда будет разным: некоторые примеры попадут в несколько подмножеств, а некоторые не попадут ни в одно.  
На основе каждой выборки строится классификатор.  
Выводы классификаторов агрегируются (путем голосования или усреднения).  
Как и при бустинге, ожидается, что результат прогноза агрегированного классификатора будет намного точнее результата прогноза одиночной модели на том же наборе данных.  

Стекинг (Stacked Generalization или Stacking) - один из самых популярных способов ансамблирования алгоритмов, т.е. использования нескольких алгоритмов для решения одной задачи машинного обучения.  
Если обучить несколько разных алгоритмов, то в задаче регрессии их среднее, а в задаче классификации — голосование по большинству  
   
/-----------Random Forest-----------/  

Другой метод построения композиций — случайный лес. В нем, в отличие от градиентного бустинга, отдельные деревья строятся независимо и без каких-либо ограничений на глубину — дерево наращивается до тех пор, пока не покажет наилучшее качество на обучающей выборке.  

Cпециальный случай бэггинга, бэггинг над решающими деревьями.

Случайный лес — это модель классификации, объединяющая некоторое количество решающих деревьев в одну композицию, за счет чего улучшается их качество работы и обобщающая способность. Деревья строятся независимо друг от друга. Чтобы они отличались друг от друга, обучение проводится не на всей обучающей выборке, а на ее случайном подмножестве. Также, для дальнейшего уменьшения схожести деревьев, оптимальный признак для разбиения выбирается не из всех возможных признаков, а лишь из их случайного подмножества. Прогнозы, выданные деревьями, объединяются в один ответ путем усреднения.  

Особенность случайного леса заключается в том, что он не переобучается по мере увеличения количества деревьев в композиции. Это достигается за счет того, что деревья не зависят друг от друга, и поэтому добавление нового дерева в композицию не усложняет модель, а лишь понижает уровень шума в прогнозах.  
   
Признак в каждой вершине дерева выбирается из случайного подмножества k из n признаков. Для регрессии k = n/3, для классификации k = sqrt(n).  
   
 RF - один из самых сильных алгоритмов машинного обучения  
 Бэггинг позволяет вычислять оценки out-of-bag:  
  - Для оптимизации числа базовых алгоритмов T  
  - Для оценивания важности признаков  
  - для выбора параметра k в RF  
   
В библиотеке scikit-learn случайные леса реализованы в классах  
 sklearn.ensemble.RandomForestClassifier (для классификации)  
 sklearn.ensemble.RandomForestRegressor (для регрессии)  
 Число деревьев задается с помощью поля класса n_estimators  
   
/-----------Градиентный бустинг над решающими деревьями-----------/

Чтобы деревья не были одинаковыми  отдельные деревья в случайном лесу обучаются по подвыборкам объектов  
Обучение отдельных деревьев на подвыборках хорошо сказывается на качестве композиции, Деревья, как правило, делают небольшой глубины  
Деревья строятся последовательно, обучение следующего дерева зависит от ошибок уже построенной композиции  
Каждое следующее дерево приближает антиградиент функции потерь для имеющейся композиции  
Функционал для оптимизации коэффициента при новом дереве распадается на сумму функционалов в отдельных листьях дерева

/-----------Градиентный бустинг-----------/

метод градиентного бустинга, который последовательно строит композицию алгоритмов, причем каждый следующий алгоритм выбирается так, чтобы исправлять ошибки уже имеющейся композиции. Обычно в качестве базовых алгоритмов используют деревья небольшой глубины, поскольку их достаточно легко строить, и при этом они дают нелинейные разделяющие поверхности.

Наиболее общий из всех бустингов  
 - Произвольная функция потерь  
 - Произвольное пространство оценок R  
 - Подходит для регрессии, классификации, ранжирования  
 - SGB (стахастический градиентный бустинг) - Лучше и быстрее.  
 - Градиентный бустинг над решающими деревьями работает лучше, чем случайный лес.

Функция потерь должна быть ограничена снизу и должна быть гладкой.  
   
AdaBoost (адаптивный бустинг) - решает задачи классификации используется экспоненциальная функция потерь. Чувствительна к выбросам.  
   
В пакете scikit-learn градиентный бустинг реализован в модуле ensemble  
GradientBoostingClassifier  
GradientBoostingRegressor  
Основные параметры, которые будут интересовать нас: n_estimators, learning_rate. Иногда может быть полезен параметр verbose для отслеживания процесса обучения.

/--------------Нейро-сетевой метод машинного обучения--------------/  
Персептрон является одной из первых моделей нейросетей

НС - композиция методов линейной регрессии и классификации.

Функции активации σ(H):  
- Пороговая функция Хевисайда. Ны выходе 1 или  
- Сигмоидная функция. На выходе вероятности 1 или  
- Гиперболический тангенс  
- Логарифмическая функция  
- Гауссовская функция  
- Линейная функция. Регрессия

Метод обратного распространения ошибки - способ обучения многослойных сетей.

/------------------Частичное обучение SSL(semi-supervised-learning)------------------/

Промежуточное положение между классификацией и кластеризацией.  
Выборка состоит из размеченной и неразмеченной  
   
/-----------------Прочее-----------------/

Задача классификации основана на аппроксимации пороговой функции потерь  
корреляция Пирсона - показывает, насколько данные величины линейно зависимы  
корреляция Спирмана -

если две переменные, между которыми изучается связь, представлены в метрической шкале, то Пирсон.  
А если одна переменная порядковая, а другая метрическая, или обе порядковые, то Спирмен.  
Нет норм. распределерния - нет смысла в Пирсоне  
Признаки, которые измерены в шкале наименований (Коэффициенты сопряженности Пирсона, Чупрова, Крамера; коэффициент корреляции А. Нильсона)  
Изучаемые признаки, которые измерены в ранговой шкале (Коэффициент корреляции Спирмена, Кэнделла, множественный коэффициент ранговой корреляции)

Logarithmic Loss - логарифмичсекая функция потерь, крайне сильно штрафует за уверенность классификатора в неверном ответе. метрика предназначена для классификаторов, выдающих оценку принадлежности классу, а не бинарные ответы.  
L(y,z) = - y * logz - (1-y) * log(1-z); z - прогноз  алгоритма

The loss function computes the error for a single training example.  
The cost function is the average of the loss functions of the entire training set.  
Функция потерь вычисляет ошибку для одного примера обучения.  
Функция стоимости - это средняя функция потерь для всего набора тренировок.  
Cost function is usually more general. It might be a sum of loss functions over your training set plus some model complexity penalty (regularization).  
Loss function is usually a function defined on a data point, prediction and label, and measures the penalty.  
Logistic Regression - Multiclass Classification (One vs all)  
Maximum likelihood  
Cross-entropy

Метрики качества регрессии  
функции потерь  
кусочно постоянная функция  
мнк  
Обобщающая способность бустинга  
аналитическое решение задачи

R2 — метрика по сути, это среднеквадратичная ошибка (MSE), нормированная на отрезок [0, 1] и обращенная так, чтобы ее наилучшим значением была единица.  
MSE (medium square error) = L(b,y) = (b - y)**2;  
MAE (medium absolute error) = L(b,y) = |b - y|;  
RMSE  
RMSLE  
RMSPE  
RBF - Radial basis function kernel  

Метод максимального правдоподобия является одним из наиболее универсальных методов оценивания неизвестных параметров распределений.  
Поэтому смысл метода максимального правдоподобия заключается в том, что в качестве оценки выбирается такое значение параметра , при котором вероятность получения данных выборочных значений , как реализации случайного вектора , максимальна.

Elastic Net

LDA - for retrieving a themes of a documents

Adaboost. Их общий подход заключался в жадном построении линейной комбинации простых моделей (базовых алгоритмов) путем перевзвешивания входных данных. Каждая последующая модель (как правило, дерево решений) строилась таким образом, чтобы придавать больший вес и предпочтение ранее некорректно предсказанным наблюдениям.

base alghoritm - desicion tree

Случайные лес - строится независмо  
Бустинг - строит деревья одно за другим  
Линейная комбинация ответов базовых алгоритмов

AdaBoost состоит из слабых алгоритмов  
Алгоритм работы:  
Зададим каждому объекту свой вес

Минусы:  
Сильная чувствительность к выбросам

class GradientBoosting(BaseEstimator)  
класс GradientBoosting будет наследником BaseEstimator

XgBoost - extreme gradient boosting - добавлен регуляризатор  
   
XGBoost docs  
CatBoost - работа с категориальными признакми  
нейронки для изображения, звуки, много текста

LightGBM работает быстрее чем xgboost

+  
масштабирование  
выбросы  
быстрее случайного леса  
меньше памяти

-  
настройка гиперпараметров  
много признаков качество падает

случайные лес хорошо работает без настройки параметров

Yes, elastic net is always preferred over lasso & ridge regression because it solves the limitations of both methods,

Ridge (L2) and Lasso (L1)

/-Large Scale Learning-/

Обучение на выборках, которые не помещаются в оперативную память  
Полный градиент тяжело и долго считать на большой выборке поэтому используют SGD

SGDClassifier - обучает разные модели методом SGD, меняя функцию потерь можно выбирать разные модели: hingeLoss - SVM, logit - LogisticRegression

LogisticRegression обучается через GD  
SGDClassifier(loss=logit) max_iter = поделить 1 миллион на длину выборки (кол-во проходов по выборке)

Epoch - кол-во проходов по выборке

Vowpal Wabbit - представляет онлайн-обучение  
 - В нем можно обучать только линейные модели.  
 - Обучающая выборка обрабатывается с помощью стахостического оптимизатора, благодаря чему можно обучаться на выборках, которые не помещаются в память  
 - Можно обрабатывать большое количество признаков за счет их хэширования (так называемый hashing trick), бладаря чему можно обучать модели даже в случаях, когда полный набор весов просто не помещается в памяти  
 - Обучение может быть распараллелено на несколько машин

когда говорят об онлайн обучении — сразу вспоминается пример с линейными моделями (потому что они почти все основаны на градиентных методах, где онлайн обучение напрашивается)  

LabelEncoding, OHE, Hashing Trick

----------------------  
От функции потерь зависит обучаемый алгоритм

/------Временные ряды---------/

Временной ряд – это последовательность значений, описывающих протекающий во времени процесс, измеренных в последовательные моменты времени, обычно через равные промежутки  

Window estimates, экспоненциальное сглаживание  
Эконометрический подход  
Feature-Based подход

Методы анализа временных рядов

Statistical Process Control - статистического управления процессами  
Включает три стадии:  
- Понимание процесса и его специфических лимитов  
- Очистка от особых причин изменчивости - действующих на систему извне  
- Мониторнинг текущих процессов, использование графиков контроля для детектирования значительных изменений

Колмогоров-Смирнов  
Принцип работы выбирается два окна и сравниваются по критериям Колмогорва-Смирнова, если параметры данных в окнах разные значит что-то случилось.  
Плюсы:  
 - Работает на периодических данных, если период меньше окна  
 - Устойчив к выбросам  
Минусы:  
 - Ложные срабатывания при наличии трендов и сезонности  
 - Нужно много данных в пределах окна

/----------Формула Бернулли----------/

Формула Бернулли - наступление события несколько раз

n - кол-во независимых испытаний  
A - вероятность наступления некоторого события одна и та же и равна p  
m - кол-во появления события А

Вероятность того, что событие А появится в n испытаниях m раз выражается формулой Бернулли

P(m,n) = Cmn * p^m * q^n-m

Cmn - сочетание = n! / m! * (n-m)!  
p - вероятность наступления A  
q - вероятность его ненаступления = 1-p

m0 - наивероятношнее число наступления событий  
np-q = m0 = np+p

/--------Метод максимального правдоподобия---------/

ММП - говорит, выбирайте ту гипотезу при которой вероятность имеющихся наблюдений максимальна

Ме́тод максима́льного правдоподо́бия или метод наибольшего правдоподобия (ММП, ML, MLE — англ. maximum likelihood estimation)  
это метод оценивания неизвестного параметра путём максимизации функции правдоподобия[1].  

Метод максимального правдоподобия соответствует многим известным методам оценки в области статистики. Например, вы интересуетесь таким антропометрическим параметром, как рост жителей России. Предположим, у вас имеются данные о росте некоторого количества людей, а не всего населения. Кроме того, предполагается, что рост является нормально распределённой величиной с неизвестной дисперсией и средним значением. Среднее значение и дисперсия роста в выборке являются максимально правдоподобными к среднему значению и дисперсии всего населения.

Для фиксированного набора данных и базовой вероятностной модели, используя метод максимального правдоподобия, мы получим значения параметров модели, которые делают данные «более близкими» к реальным. Оценка максимального правдоподобия даёт уникальный и простой способ определить решения в случае нормального распределения.

/------ODS Random Forest------/

добавить

RF объединяет два подхода Random Subspace, Bootstrap  
т.е. он выбирает подмножетсва объектов и подмножества признаков и на этих сэмплах обучает DT

Random Subspace (случайные подпространства)  
Bootstrap

max_features = советуют брать корень из числа признаков

хорошо работает из коробки т.е. несильно чувствителен к гиперпараметрам  
Вот бустинг чувствиетлен к настройке гиперпараметров

минусы RF  
медленно работает, бустинг работает быстрее  
плохо работает на sparse

если у нас sparse, то нужно использовать линейные модели

[https://alexanderdyakonov.wordpress.com/2016/08/03/python-%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8/](https://alexanderdyakonov.wordpress.com/2016/08/03/python-%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8/)

[https://www.kaggle.com/general/](https://www.kaggle.com/general/)

Предположим теперь, что мы знаем закон распределения случайной величины x, то есть знаем, что случайная величина x может принимать значения x1, x2, ..., xk с вероятностями p1, p2, ..., pk.

Математическое ожидание Mx случайной величины x равно

Долгая краткосрочная память - Long short-term memory; LSTM) — разновидность архитектуры рекуррентных нейронных сетей,  

/----FEATURES--------/

feature extraction and feature engineering – превращение данных, специфических для предметной области, в понятные для модели векторы;  

feature transformation – трансформация данных для повышения точности алгоритма;  

feature selection – отсечение ненужных признаков.  

Выбор признаков (Feature selection) - низковариативные признаки скорее хуже, чем высоковариативные. Так можно придти к идее отсекать признаки, дисперсия которых ниже определенной границы.

from sklearn.feature_selection import SelectKBest, f_classif

In : x_data_kbest = SelectKBest(f_classif, k=5).fit_transform(x_data_generated, y_data_generated)

In : x_data_varth = VarianceThreshold(.9).fit_transform(x_data_generated)

Отбор с использованием моделей  
какая-нибудь "деревянная" композиция (например, Random Forest) или линейная модель с Lasso

Наконец, самый надежный, но и самый вычислительно сложный способ основан на банальном переборе: обучаем модель на подмножестве "фичей", запоминаем результат, повторяем для разных подмножеств, сравниваем качество моделей. Такой подход называется Exhaustive Feature Selection.

Перебирать все комбинации – обычно слишком долго, так что можно пробовать уменьшить пространство перебора. Фиксируем небольшое число N, перебираем все комбинации по N признаков, выбираем лучшую комбинацию, потом перебираем комбинации из N+1 признаков так, что предыдущая лучшая комбинация признаков зафиксирована, а перебирается только новый признак. Таким образом можно перебирать, пока не упремся в максимально допустимое число признаков или пока качество модели не перестанет значимо расти. Этот алгоритм называется Sequential Feature Selection.