Генеральная совокупность - все те объекты в рамках, которых мы собираемся делать исследование.  
Выборка - часть ген.совокупность на которой проводят исследования  
Репрезентативность выборки - модель генеральной совокупности, обадает свойствами генеральной выборки.  
   
  p меньше 0,05 Следовательно Ho отклоняем  
  M - среднее значение выборки  
  μ - среднее значение ГС  
    
Методы формирования репрезентативной выборки:  
   - Простая случайная выборка  
   - Стратифицированная выборка:  
       1. Сначала делим ГС на группы по признаку (к прим. М/Ж)  
       2. Затем из каждой группы методом случайной выборки выбираем элементы  
   - Групповая выборка (cluster sample):  
       1. Делим ГС на кластеры, но группы очень сильно похожи между собой (Делим город на районы)  
       2. Из нескольки кластеров делаем выборку

Типы переменных  
      Количественные  
          - непрерывные  
          - дискретные  
      Номинативные (Качественные) 

Виды шкал:  
Номинальная (Пол, Фамилия, Номера телефона и пр.) - Для идентификации объектов  
Порядковая  (Рейтинг, степень ожога, возростная группа) - все что можно упорядочить  
Количественная (Сумма покупки, возраст, объем продаж и пр.)

Преобразование шкал:  
Порядковая -> Номинальная  
Количественная -> Порядковая/Номинальная  
*Обратное преобразование невозможно 

Описательная статистика:  
       
Частотная гистограмма  - позволяет понять форму распределения нашего количественного признака  
Если наше распределенние имеет вид нормального распределения, то мы можем использовать любую из мер центральной тенденции  
Если присутствуют заметные выбросы, распределение асимметрично вместо среднего значения лучше использовать моду или медиану в качестве центральной тенденции    
       
Меры центральной тенденции:  
 - Мода  
 - Медианна (делит упорядоченное множество данных пополам)  
 - Среднее значение (выборочное среднее значение X с верхним подчеркиванием или μ для ГС)(Сумма значений на кол-во значений)  
   
Мера изменчивости (про изменчивость признака и его вариативность)  
 - Размах (R = Xmax - Xmin)  
 - Дисперсия - средний квадрат отклонений индивидуальных значение признака от их средней величины в выборке. (Насколько в среднем наши значения отклоняются от среднего значения по выборке)  
     D = E(Xi - X)^2/n (для того чтобы избавиться от отрицательных отклонений мы возвели их в квадрат иначе сумма отклонений дала бы нам ноль при этом показатель диспресии будет привышать реальное среднее отклонение наших наблюдений от среднего по выборке, чтобы вернуться к исходным единицам измерениям нужно извлечь квадратный корень от D)  
     Корень от D = σ (Среднеквадратическое отклонение | Стандартное отклонение) и оно показывает реальное среднее значение наших отклонений от среднего значения по выборке)  
     Среднеквадратическое отклонение | Стандартное отклонение для ГС это σ  
     Среднеквадратическое отклонение | Стандартное отклонение для выборки это sd (standard deviation)  
      
 Свойства Дисперсии  
    Dx+c = Dx - Если каждому наблюдению выборки прибавить некоторое число, то ни дисперсия ни стандартное отклонение не измениться  
    SDx+c = SDx  
     
    Dx*c = Dx*c^2;  
    SDx*c = SDx*c  
     
Квантили распределения - значения признака, которые делят упорядоченные данные на некоторое число равных частей.  
Квартили распределения - это три точки, которые делят упорядоченные данные на 4 части.  
(Квартили строятся находя медиану, потом находится медианна для левой и правой части выборки)  
Использую квартили можно построить график box-plot

/----------Стандартизация / z-преобразование----------/

Стандартизация или z-преобразование - преобразование полученных данных в стандартную Z - шкалу, где среднее Mz = 0, а дисперсия Dz = 1.  
Zi = Xi - X(c верхним подчеркивание)/sd  
Нужно из каждого наблюдения выборки отнять среднее значение X(c верхним подчеркивание) и поделить на стандартное отклонение,  
    когда отнимаем среднее значение от среднего значения получиться 0 Mz = 0.  
Если отдельное наблюдение меньше, чем выборочное среднее, то соответствующее z - значение будет  отрицательным  
Такое преобразование не изменит форму распределения

σ (стандартной отклонение)  
Правило трех сигм

1сигм = 68% наблюдений  
1.96сигм = 95% наблюдений  
3сигм = 100% наблюдений

помните мы говорили, что 95% всех наблюдений лежат приблизительно в диапазоне +/- 2 sd от среднего. Так вот 1,96 - это более точная оценка!)

Z - преобразование помогает узнать какой процент наблюдений лежит в любом интересующем нас диапазоне выборки.  
Пример:  
Есть выборка со средним значением X(с верхним подчеркиванием) =  
Стандартное отклонение =  
Вопрос: Сколько процентов наблюдений лежит в области со значениями от  
Делаем z - преобразование: 154-150/8 = 0,  
Использую Таблицу нормального распределения (Normal probability table, Z-table) находим для значения z = 0,5, число 0,3085. Итого в диапазоне от 154 кол-во наблюдений равно 30%.

Нормальное распределение  
    Унимодальное  
    Симметричное  
    Отклонение наблюдений от среднего подчиняются вероятностному закону 'правило 3 сигм'

  
/----------Центральная предельная теорема-----------/  
   
ЦПТ используется для статистической проверки гипотез.  
     
Есть некоторый признак, который имеет нормальное распределение и среднее значение 0, многократно делаем выборку из генеральной совокупности этого признака. Внутри каждой из выборок мы считаем выборочное среднее, мы увидим, что выборочное среднее изменяется от выборки к выборки.

Далее мы строим распределение выборочных средних значений и увидим, что среднее значение распределения выборочных средних значений будет около 0 (хороший результат т.к. у ГС ср.значение 0) / Среднее всех средних  
Стандартное отклонение этого распределения называется стандартной ошибкой среднего и показывает насколько в среднем выборочное среднее отклоняется от среднего значения ГС  
Увеличение объема выборок приводит к тому, что среднее выборок стремиться к реальному среднему значению ГС. (Чтобы это отразить в формуле стандартное отклонение делят на корень из наблюдений)

Стандартная ошибка среднего se = σ(Стандартное отклонение ГС) / корень(n)  
n - кол-во выборок/наблюдений

Формулировка ЦПТ -

ЦПТ позволяет нам основываясь только на одной выборке предположить как бы вели себя все выборочные средние  
Нужно использовать формулу 'стандартной ошибки среднего' для одной выборки из генеральной совокупности  
Где кол-во наблюдений n = 100, σ = 5, среднее значение = 3;  
se = 5/корень 100 = 5/10 = 0.5;  
Мы можем предположить, что все выборочные средние распределились бы со стандартным отклонением = 0.5;

Условие ЦПТ  
Число элементов выборки, n > 30;

Стандартная ошибка среднего - это среднеквадратическое отклонение распределения выборочных средних  
Стандартная ошибка среднего тем меньше, чем больше объем выборки и меньше вариативность исследуемого признака  
Чем меньше стандартная ошибка среднего, тем реже выборочные средние будут сильно отклоняться от среднего в генеральной совокупности  
Распределение выборочных средних является нормальным, со средним равным среднему значению признака в генеральной совокупности

/-----------Доверительные интервалы для средних значений-----------/

Цель статистики - возможность сделать вывод относительно генеральной совокупности основываясь только на выборочных данных.

У нас есть генеральная совокупность 1 млн.чел. которую мы не можем исследовать  
Также мы имеем выборку со средним значением x = 100 и sd = 4 (стандартное отклонение)  
Задача узнать среднее значение для генеральной совокупности  
Проблема в том что мы не можем абсолютно точно сказать это среднее значение, но мы можем рассчитать доверительный интервал, который включает в себя интересующий нас параметр  
Используя ЦПТ мы хотим узнать среднее значение генеральной совокупности  
Вспоминаем свойства ЦПТ если мы многократно выполняем выборку, то средние этих выборок распределялись бы вокруг среднего генеральной совокупности со стандартной ошибкой среднего se = sd/корень(n)  
Вспоминаем свойства нормально распределения, где в диапазоне 1.96sd = лежит 95% всех наблюдений  
Поэтому X +- 1.96se (является доверительным интервалом, в котором гарантированно находиться среднее значение ГС

Расчет 95% интервала = X +/- 1.96 * sd/корень(n)

Пример  
Есть выборка  
Среднее значение X = 100;  
Стандартное отклонение sd = 4;  
Число участников/число наблюдений n = 64;

Считаем стандартную ошибку se = 4/8 = 0.5;

Согласно нормальному распределению 95 % наблюдений лежат в интервале +-1.96sd  
Согласно нормальному распределению 99 % наблюдений лежат в интервале +-2.58sd

Наш 95% интервал [X - 1.96*0.5 : X + 1.96*0.5]

Мы можем быть на 95% уверены, что среднее значение в генеральной совокупности принадлежит рассчитанному доверительному интервалу.  
Если многократно повторять эксперимент, для каждой выборки рассчитывать свой доверительный интервал, то в 95 % случаев истинное среднее будет находиться внутри доверительного интервала.

/-----------Идея статистического вывода(статистической проверки гипотез), p-уровень значимости-----------/

Статистическая проверка гипотез основывается на ЦПТ. Благодаря ЦПТ мы можем предположить как бы вели себя все выборочные средние и основываясь на этом мы можем  
расчитать вероятность получения такого или иного отклонения

Ho - нулевая гипотеза  
H1 - альтернативная гипотеза

Сначало проверяем Но, предполагаем, что ничего не изменилось. Если р меньше 0,05, то Но отклоняем. Если р больше 0,05, то p-уровня значимости не позволяет нам отклонить Но.

Значение p-уровня значимости (p-value) — это вероятность получить такие или более выраженные различия при условии, что в генеральной совокупности никаких различий на самом деле нет.  

p-уровня значимости -  не позволяет сказать с какой вероятностью верна Но.

Ошибка первого рода - отклонили нулевую гипотезу  
Ошибка второго рода - не отклонили нулевую гипотезу

Использование доверительных интервалов зачастую рассматривают, как альтернативный способ проверки гипотез.

/-----------Пример расчета p-уровеня значимости-----------/

В среднем слушатели курса по введению в статистику набирают 115 баллов, однако, в 2015 году средний балл  случайно выбранных 144 участников составил 118 со стандартным отклонением равным 9. Рассчитайте p уровень значимости для проверки нулевой гипотезы о том, что среднее значение баллов в 2015 году равняется 115.

Имеем  
М = 115 (старое среднее)  
X = 118 (новое среднее)  
N = 144 (кол-во элементов в выборке)  
sd = 9;

Проверяем гипотезы  
Но - ничего не изменилось и новое среднее не отличается от старого среднего.  
Н1 - изменения есть.  
если Но отклоняем т.е. у нас были получены статистически значимые различия.

Предположим, что верна Но - тогда согласно ЦПТ выборочные средние распределились вокруг среднего по ГС(μ) со стандартной ошибкое среднего se = sd / корень(N) = 9/12 = 0;  
Далее определим насколько далеко наше выборочное среднее отклонилось от предполагаемого среднего по ГС(μ) в единицах стандартного отклонения. Для этого делаем z преобразование.  
z = X-μ/se = 118-115 / 0.75 = 4;  
Это озночает, что если бы в ГС среднее значения на самом дела равнялось μ, то наше выборочное среднее Х отклонилось от среднего по ГС(μ) на +4σ

Далее использую Distribution Calculator определим вероятность такого отклонения  
μ = 0, sd =1, a b = z, find_area = both tails  
Получили p меньше 0,05. Следовательно Ho отклоняем

Также можно посчитать через доверительный интервал  
Наш 95% интервал [X - 1.96*se : X + 1.96*se] = [116.5 : 117.7] М в этот интервал не входит, поэтому Но отклоняем.

/-----------Распределение Стьюдента (Т-распределение)-----------/   

Если мы не знаем стандартное отклонение по ГС (σ), то всегда используем Т-распределение.  
   
t = X-μ / sd/sqrt(n) # t - распределение

Когда кол-во наблюдений невелико, нарушается предположение о том, что выборочные средние будут вести себя в соответствии с нормальным законом.  
Если число наблюдений невелико и стандартное отклонение по ГС (σ) нам неизвестно, то всегда используется распределение Стьюдента (t - distribution)  
Число степеней свободы df = n - 1. С увеличением df t-распределение стремиться к нормальному.

/-----------t-критерий Стьюдента или парный t-тест-----------/ 

Позволяет сравнивать две выборки между собой(два выборочных средних)

Сравниваем две выборки из ГС: M - среднее значение, sd - стандартное отклонение, n - число элементов в выборке

Проверить, являются ли различия статистически значимыми  
         M      SD    N  
Вид 1 | 89.9 | 11.3 | 20;  
Вид 2 | 80.7 | 11.7 | 20;  
   
Сформулируем гипотезы:    
Ho: M1 = M2, где (μ1 - μ2) = 0;  
H1: M1 != M  
    
Рассчитаем t-критерий

se = корень((SD1**2 / N1) + (SD2**2 / N2)) = корень(127.69 / 20 + 136.89 / 20) = корень(6.3845 + 6.8445) = 3.63;  
    
t = M1 - M2 / se = 9.2 / 3.63 = 2.53 . Это значит, что разница между нашими средними отклонилась от предполагаемого среднего значения в ГС на 2.5σ  
    
df = N1 + N2 - 2 = 40 - 2 = 38 Число степеней свобод  
    
Рассчитаем вероятность (p-value) через сайт Distribution Calculator ([https://gallery.shinyapps.io/dist_calc/](https://gallery.shinyapps.io/dist_calc/))  
P(X = -2.5 or X 2.5) = 0.0169;

Т.к. p-value меньше 0,05, Ho отклоняем и принимаем H1;

/----Расчет доверительно интервада 95% через t-распределение----/

X = 89;  
sd = 11;  
n = 20;

95% наблюдений у t-распределения 2.093 вместо 1.96 ([https://www.medcalc.org/manual/t-distribution.php](https://www.medcalc.org/manual/t-distribution.php))

[X - 2.093 * sd/sqrt(20) : X + 2.093 * sd/sqrt(20)]

/------QQ plot (Quantil-Quantil Plot) -----/

Если предполагается, что один из параметров зависит от другого, то обычно значения независимого параметра откладывается по горизонтальной оси, а значения зависимого — по вертикальной. Диаграммы рассеяния используются для демонстрации наличия или отсутствия корреляции между двумя переменными.  

Оценка того, насколько наши данные распределены нормально.

Варианты оценки:  
1. Построить гистограмму частот и наложить график нормального распрдеделния  
2. QQ Plot

QQ plot показывает наскольно наши выборочные значения соответствую предсказанным. Все точки должны лежать на прямой линии

QQ Plot используют, когда недостаточно наблюдений для построения гистрограммы.  
    
Также для проверки нормальности используются тесты:  
Колмагорова-Смирнова  
Шапиро-Вилк  
    
Важно проверять распределение на нормальность, т.к. выбросы могут оказать значительное влияние на результаты t-теста    
Непараметрический U-критерий Манна -Уитни не столь чувствителен к наличию выбросов по сравнению с t-тестом 

  
/------------Однофакторный дисперсионный анализ-------------/     
     
В исследованиях возникает необходимость сравнить несколько групп между собой. В таком случае мы можем применять однофакторный дисперсионный анализ.  
Изменчивость наших данных может быть обусловленна двумя вещами: изменчивость внутри групп и изменчивость между групп  
     
1 | 2 |  
---------  
3 | 5 | 7;  
1 | 3 | 6;  
2 | 4 | 5;  
   
Формулируем гипотезы:  
  Ho: M1 = M2 = M3 # никаких значимых различий между группами нет  
  H1: M1 != M2 != M  
    
X(два подчеркивания) - среднее значение всех наблюдений  
X(два подчеркивания) = 3+1+2+5+3+4+7+6+5 / 9;  
     
SST (Total Sum of Squares) - общая сумма квадратов, характеризует насколько высока изменчивость наших данных без учета разделения их на группы. Похож на дисперсию.  
SSW - изменчивость внутри групп  
SSB - изменчивость между групп

SST = (3-4)^2 + (1-2)^2 + (2-4)^2 + ... + (5-4)^2 = 30;  
df = N-1 = 8;

F = (SSB/m-1) / (SSW/N-m) = 12 # F распределение или распределение Фишера

Теоретическое распределение F-значения в дисперсионном анализе не является нормальным, а подчиняется распределению Фишера (F distribution). Вы можете посмотреть, как изменяется форма этого распределения в зависимости от числа степеней свободы (то есть от количества групп и общего числа наблюдений). Обратите внимание, что F-значение всегда является положительным, поэтому, в отличие от t-критерия, мы рассчитываем вероятность отклонения только в правую сторону.

Чем больше дисперсия внутри групп, тем больше значение внутригруппового квадрата (при неизменном количестве наблюдений)

Отклонение нулевой гипотезы позволяет нам сделать следующий вывод:  Как минимум две группы значимо различаются

/------------Множественные сравнения-------------/ 

Ошибка первого рода получить значимые различие там где их нет

Поправка Бенферони применяется там, где можно получить ошибку первого рода.  
Делим уровень значимости, который хотим удержать, на кол-во сравнений.  
Также Бенферонни уничтожает значимый уровень значимости

Вычисление попарных сравнений. Дано 5 групп, сколько получиться попарных сравнений - 5*4 / 2;

/------------ANOVA-------------/

Проверка равенства СРЕДНИХ значений КОЛИЧЕСТВЕННОЙ шкалы в нескольких группах

Требования -  
- Данные внутри сравниваемых подгрупп нормально распределены  
-

Построить Box-Plot

Turkey honest significant difference for unequal N

Дисперсионный анализ(Analisys of Variance)

One-way ANOVA between groups: used when you want to test two groups to see if there’s a difference between them.  

Если вид распределения или функция распределения выборки нам заданы, то в этом случае задача оценки различий двух групп независимых наблюдений может решаться с использованием параметрических критериев статистики: либо кри­терия Стьюдента (t), если сравнение выборок ведется по сред­ним значениям (X и У), либо с использованием критерия Фишера (F), если сравнение выборок ведется по их дисперсиям.

Использование параметрических критериев статистики без предварительной про­верки вида распределения может привести к определенным ошибкам в ходе проверки рабочей гипотезы.  
Для преодоления указанных трудностей в практике педагоги­ческих исследований следует использовать непараметрические критерии статистики, такие, как критерий знаков, двухвыборочный критерий Вилкоксона, критерий Ван дер Вардена, критерий Спирмена, выбор которых, хотя и не требует большого числа членов выборки и знаний, вида распределения, но все же зависит от целого ряда условий.

Непараметрические критерии статистики -  свободны от допущения о законе распределения выборок и базируются на предположении о независимости наблюдений.

Критерий позволяет найти вероятность того, что оба средних значения в выборке относятся к одной и той же совокупности. Данный критерий наиболее часто используется для проверки гипотезы: «Средние двух выборок относятся к одной и той же совокупности».  
При использовании критерия можно выделить два случая. В первом случае его применяют для проверки гипотезы о равенстве генеральных средних двух неза­висимых, несвязанныхдвухвыборочный t-критерий). В этом случае есть контрольная группа и экспериментальная (опытная) группа, количество испытуемых в группах может быть различно.  
Во втором случае, когда одна и та же группа объектов порождает числовой матери­ал для проверки гипотез о средних, используется так называемый парный t-критерий. Выборки при этом называют зависимыми, связанными.

   /------------Корреляция  и Ковариация-------------/[http://rpsychologist.com/d3/correlation/](http://rpsychologist.com/d3/correlation/)

cov = SUM( (Xi - X(подчеркивание)) * (Yi - Y(подчеркивание)) ) / N - 1;

rxy = cov / σx * σy # Это сделано для того, чтобы все значения коэффициента корреляции находились в промежутке [-1 ; +1]

Корреляция(rxy) — статистическая взаимосвязь двух или нескольких количественных переменных. Принимает значения от [-1 до 1]. Существует положительная и отрицательная корреляция. Коэффициент корреляции Пирсона.  

Если ковариация/корреляция положительна, то с ростом одной случайной величины, вторая имеет тендению возрастать, а если знак отрицательный — то убывать.  

Однако только по абсолютному значению ковариации нельзя судить о том, насколько сильно величины взаимосвязаны, так как её масштаб зависит от их дисперсий. Масштаб можно отнормировать, поделив значение ковариации на произведение стандартных отклонений. При этом получается так называемый коэффициент корреляции Пирсона, который всегда находится в интервале от −1 до 1.  

Величина ковариации зависит от единиц измерения рассматриваемых случайных величин. Если одна в рублях, а другая в долларах, то ковариация будет в руб/долл.  
И непонятно, большая она или маленькая, так как не с чем сравнивать. А корреляция — безразмерная величина и ее понятно с чем сравнивать.  
     
Посчитать коэффициент корреляции  
X | Y  
4 | 2;  
5 | 1;  
2 | 4;  
3 | 3;  
1 | 5;  

1. Считаем σx и σy  
σx = sqrt(2)  
σy = sqrt(2)

2. Считаем ковариацию  
cov = -2;

3. Считаем корреляцию  
rxy = cov / σx * σy = -1;

Коэффициент Корреляции Пирсона не работает для нелинейной зависимости переменных. Выбросы уничтожают корреляцию.  
Решение проблемы выбросов:  
Коэффициент корреляции Спирмана - использует ранжирование.

основные требования к данным при использовании коэффициента корреляции Пирсона:  
Нормальное распределение переменных (значительные выбросы могут негативно сказаться на значении коэффициента корреляции)  
Линейная взаимосвязь двух переменных

   Линейная взаимосвязь позволяет применить регрессионный анализ. Регрессионную прямую называют линией тренда

Коэффициент детерминации R^2 - равен квадрату корреляции, показывает в какой степени дисперсия одной переменной обусловлена, влиянием другой переменной. Принимает значения от [0 до 1].

R^2 - коэф.детерминации показывает какой процент дисперсии объесняется нашей моделью.  
R = 1 - все наши наблюдения лежат на регрессионной прямой.  
Чем больше коеф. детерминации - тем лучше модель предсказывает значение зависимой переменной.

R2 = 1 - SSres / SStotal  
SSres = сумма квадратов остатков до регрессионной прямой  
SStotal =  сумма квадратов расстояний наблюдений до среднего(средней линии)

/------------Регрессия-------------/

С каждым единичным положительным изменением независимой переменной, ожидаемые значения зависимой переменной увеличиваются на (Slope)

Множественная регрессия  
Позволяет исследовать влияние сразу нескольких независимых переменных на одну зависимую переменную.

Большое количество независимых переменных не гарантирует хорошее качество модели

Коэффициент Slope чем больше, тем сильнее влияет на зависимую переменную.

y = b0 + b1*x1 + bn*xn

Требования к данным  
Линейная зависмиость зависимых переменных с независимой переменной  
Нормальное распределение остатков  
Гетероскедастичность - это напротив, непостоянная изменчивость остатков. То есть мы напротив должны ее избегать в данных!  
Проверка на мультиколлинеарность - отсутствие корреляции между зависимыми переменными  
Нормальное распределение переменных

если две независимые переменные сильно взаимосвязанны, то достаточно только одной чтобы объяснить зависимую переменную

Adjusted R^2(Исправленный R квадрат) - в случае множественной регрессии подсчитывается исправленный R^2. Предсказательная сила модели

Коэффициент 3.66(slope)  при независимой переменной cost (бюджет фильма) демонстрирует нам:  
Насколько изменяется ожидаемое значение кассовых сборов фильма при единичном изменении независимой переменной cost при условии, что все остальные независимые переменные не изменяются

Очень сильная корреляция между независимыми переменными может негативно повлиять на результаты регрессионного анализа  
Значение коэффициента b0 (intercept) демонстрирует, чему равняется предсказанное значение зависимой переменной, при условии что все независимые переменные равны нулю  
Исправленный коэффициент детерминации рассчитывается при включении в регрессионную модель нескольких независимых переменных

Логистическая регрессия позволяет построить регрессионную модель, где номинативная переменная с двумя градациями является зависимой переменной

При помощи кластерного анализа можно группировать наблюдения, основываясь на значениях нескольких количественных переменных.   

 Количественные  
Номинативные переменные - Категориальные 1/0;  
Ранговые переменные - 1/2/3;

Исследование взаимосввязи:  
 - Переменные количественные, то лучше использовать коэф.корреляции или линейную регрессию для проверки взаимосвязи между ними.  
 - Одна переменная номинативная, а другая количественная , то используют т-тест или дисперсионный анализ.  
 - Переменные номинативны, то коэф. Пирсона и критерий Стьюдента не применяются.

    Дух божий нашёл тончайшую отдушину в этом чуде анализа, уроде из мира идей, двойственной сущности, находящейся между бытием и небытием, которую мы называем мнимым корнем из отрицательной единицы

Схема Лапласса (классическое определение вероятности) P = кол-во благоприятных исходв / кол-во всех равновероятных исходов