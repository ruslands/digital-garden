[https://habr.com/ru/company/oleg-bunin/blog/313330/](https://habr.com/ru/company/oleg-bunin/blog/313330/)

принципы работы с данными  
-независимое обрабатываем независимо  
-обрабатываем там где храним  
-сложный процесс разбиваем на несколько простых

mapReduce  
парадигма обработки больших данных  
имеет много имплементаций(open source)

hadoop - реализует map reduce парадигму

три шага обработки в mapreduce  
1. map - исполнитель(mapper) для каждого объекта выполняет функцию map(функция выдает множество пар ключ - значение)  
2. shuffle - распределенная сортировка объектов объединяет объекты по одному ключу определяется не явно.  
3. reduce - на reduce поступают данные с одним ключом от shuffle(группировка)  
функция map и reduce - явно определяет программист.  
 одно ядро(одна машина) - один mapper и reduce  
shuffle перемещение данных с машины на машину