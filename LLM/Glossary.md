## ‚ö° vLLM

–ë—ã—Å—Ç—Ä—ã–π inference –¥–≤–∏–∂–æ–∫ LLM.
**PagedAttention** ‚Äî —ç–∫–æ–Ω–æ–º–∏—è GPU –ø–∞–º—è—Ç–∏.
OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API `/v1/completions`.

---

## üß† Triton (NVIDIA)

Inference server –¥–ª—è PyTorch/TF/ONNX –º–æ–¥–µ–ª–µ–π.
**–§–∏—á–∏:** GPU batching, gRPC/HTTP, Prometheus metrics.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ MLops –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö.

---

## üöÄ SGLang

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π runtime –¥–ª—è LLM.
**–§–æ–∫—É—Å:** multi-GPU, –Ω–∏–∑–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞, OpenAI API.
–ü–æ—Ö–æ–∂ –Ω–∞ vLLM, –Ω–æ –±—ã—Å—Ç—Ä–µ–µ –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.

---

## üîó LangChain

–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** Chains, Agents, Memory, Tools.
**–ü—Ä–∏–º–µ—Ä:** —á–∞—Ç-–±–æ—Ç—ã, reasoning –∞–≥–µ–Ω—Ç—ã, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è API.

---

## üìö LlamaIndex

–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∫ LLM (RAG).
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** Document, Index, Retriever.
–†–∞–±–æ—Ç–∞–µ—Ç —Å FAISS, Qdrant, Weaviate.

## ‚ö° vLLM

**–ß—Ç–æ —ç—Ç–æ:**
High-performance inference engine –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**

* –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –¥–ª—è **Serving LLMs** (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –æ–±—É—á–µ–Ω–∏—è).
* **PagedAttention** ‚Äî —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU –ø–∞–º—è—Ç—å.
* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ **OpenAI API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞** (`/v1/completions`).
* –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å **HuggingFace Transformers** –∏ **Triton Inference Server**.
* –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ **tensor/async parallelism**.

**–ü—Ä–∏–º–µ—Ä:**

```bash
python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3-8B
```

---

## üö¶ Triton Inference Server (NVIDIA)

**–ß—Ç–æ —ç—Ç–æ:**
–°–µ—Ä–≤–µ—Ä –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–µ–π (LLM, CV, ASR –∏ –¥—Ä.).

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:** TensorRT, PyTorch, ONNX Runtime, TensorFlow, vLLM.

**–§—É–Ω–∫—Ü–∏–∏:**

* –ú—É–ª—å—Ç–∏-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞.
* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ batching.
* gRPC / HTTP API.
* Prometheus-–º–µ—Ç—Ä–∏–∫–∏.
* GPU-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ CUDA / TensorRT.

**–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**
–≤ MLops –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ inference —Å–µ—Ä–≤–∏—Å–∞.

---

## üßÆ SGLang

**–ß—Ç–æ —ç—Ç–æ:**
Runtime-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è LLM (–∞–Ω–∞–ª–æ–≥ vLLM, –Ω–æ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ **graph optimization** –∏ **multi-GPU inference**).

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**

* Optimized **graph-based** execution.
* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ **streaming output**.
* –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å **OpenAI API**.
* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ **Llama**, **Mistral**, **Qwen**, **Phi** –∏ –¥—Ä.

**–°—Ü–µ–Ω–∞—Ä–∏–π:**
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è production-LLM —Å–µ—Ä–≤–µ—Ä–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∏ –Ω–∏–∑–∫–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π.

---

## üîó LangChain

**–ß—Ç–æ —ç—Ç–æ:**
–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π (chain‚Äô—ã, –∞–≥–µ–Ω—Ç—ã, memory, tools).

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏:**

* **LLMs** ‚Äî –æ–±—ë—Ä—Ç–∫–∏ –Ω–∞–¥ OpenAI, Anthropic, HuggingFace.
* **Prompt Templates** ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã.
* **Chains** ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–∑–æ–≤–æ–≤ –º–æ–¥–µ–ª–µ–π.
* **Agents** ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π.
* **Memory** ‚Äî —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞.
* **Retrievers / Tools** ‚Äî –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö (API, –ë–î).

**–ü—Ä–∏–º–µ—Ä:**

```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

template = "Translate this to French: {text}"
prompt = PromptTemplate.from_template(template)
chain = LLMChain(llm=OpenAI(), prompt=prompt)
print(chain.run(text="Hello"))
```

---

## üìö LlamaIndex (–±—ã–≤—à. GPT Index)

**–ß—Ç–æ —ç—Ç–æ:**
–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è **–≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö** –∫ LLM —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å—ã.

**–û—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:**

* **Document / Node / Index** ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.
* **VectorStore** ‚Äî —Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
* **Retriever** ‚Äî –≤—ã–±–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
* **Query Engine** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤.
* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ **LangChain –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏**, **Weaviate**, **Qdrant**, **FAISS**.

**–ü—Ä–∏–º–µ—Ä:**

```python
from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex
docs = SimpleDirectoryReader("./data").load_data()
index = GPTVectorStoreIndex.from_documents(docs)
query_engine = index.as_query_engine()
response = query_engine.query("Summarize this document.")
```

---

## üîç Haystack

**–ß—Ç–æ —ç—Ç–æ:**
Open-source NLP/LLM-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ—Ç deepset.ai –¥–ª—è **retrieval-augmented generation (RAG)**.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**

* –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (Retriever, Reader, Generator).
* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Elasticsearch, FAISS, Milvus.
* –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —á–∞—Ç–æ–≤, Q&A, –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º.
* –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LangChain –∏ HuggingFace.
* REST API –∏ FastAPI-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.

**–ü—Ä–∏–º–µ—Ä:**

```python
from haystack.nodes import EmbeddingRetriever
from haystack.document_stores import FAISSDocumentStore
from haystack.pipelines import DocumentSearchPipeline

doc_store = FAISSDocumentStore()
retriever = EmbeddingRetriever(document_store=doc_store, embedding_model="sentence-transformers/all-MiniLM-L6-v2")
pipeline = DocumentSearchPipeline(retriever)
result = pipeline.run(query="What is Kubernetes?")
```

---

## ‚úÖ –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ LLM Frameworks

| Framework      | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ   | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏                                       |
| -------------- | ------------ | ------------------------------------------------- |
| **vLLM**       | Serving      | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è inference, OpenAI API —Å–æ–≤–º–µ—Å—Ç–∏–º |
| **Triton**     | Serving      | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤, GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è     |
| **SGLang**     | Serving      | –í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å, multi-GPU                       |
| **LangChain**  | App Logic    | Chains, agents, memory                            |
| **LlamaIndex** | Data Layer   | RAG, –∏–Ω–¥–µ–∫—Å—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤                           |
| **Haystack**   | RAG / Search | –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å retriever/reader          |

## ‚ö° vLLM

### ‚ùì–ß—Ç–æ –¥–µ–ª–∞–µ—Ç vLLM?

> –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π inference –¥–≤–∏–∂–æ–∫ –¥–ª—è LLM (–Ω–µ –æ–±—É—á–µ–Ω–∏–µ, –∞ –≤—ã–¥–∞—á–∞ –æ—Ç–≤–µ—Ç–æ–≤).

### ‚ùì–ì–ª–∞–≤–Ω–∞—è —Ñ–∏—á–∞?

> PagedAttention ‚Äî —ç–∫–æ–Ω–æ–º–∏—è GPU –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.

### ‚ùìAPI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å?

> –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenAI API (`/v1/completions`, `/v1/chat/completions`).

---

## üéØ Triton Inference Server

### ‚ùì–ß—Ç–æ —ç—Ç–æ?

> –°–µ—Ä–≤–µ—Ä NVIDIA –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (LLM, CV, ASR –∏ –¥—Ä.) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π PyTorch, TensorRT, ONNX, TF.

### ‚ùì–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞?

> Multi-framework, batching, GPU-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, Prometheus-–º–µ—Ç—Ä–∏–∫–∏.

---

## üöÄ SGLang

### –î–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω?

> –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π runtime –¥–ª—è LLM-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π multi-GPU –∏ graph execution.

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏?

> –ë—ã—Å—Ç—Ä–µ–µ vLLM –ø—Ä–∏ —Å–ª–æ–∂–Ω—ã—Ö –≥—Ä–∞—Ñ–∞—Ö, —Å—Ç—Ä–∏–º–∏–Ω–≥, OpenAI API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å.

---

## LangChain

### –ß—Ç–æ –¥–µ–ª–∞–µ—Ç LangChain?

> –§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å —Ü–µ–ø–æ—á–∫–∞–º–∏ (`Chains`), –∞–≥–µ–Ω—Ç–∞–º–∏ (`Agents`), –∏ –ø–∞–º—è—Ç—å—é (`Memory`).

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è?

> –°–æ–∑–¥–∞–Ω–∏–µ —á–∞—Ç-–±–æ—Ç–æ–≤, reasoning —Å–∏—Å—Ç–µ–º, API-–∞–≥–µ–Ω—Ç–æ–≤.

---

## LlamaIndex

### –ß—Ç–æ –¥–µ–ª–∞–µ—Ç?

> –°–æ–µ–¥–∏–Ω—è–µ—Ç –≤–Ω–µ—à–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å LLM (RAG).
> –°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –∏ —Ö—Ä–∞–Ω–∏—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É.

### –° —á–µ–º —Ä–∞–±–æ—Ç–∞–µ—Ç?

> FAISS, Qdrant, Weaviate, Pinecone, LangChain.

---
## Haystack

### –ß—Ç–æ –¥–µ–ª–∞–µ—Ç Haystack?

> Open-source —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è Retrieval-Augmented Generation –∏ Q&A —Å–∏—Å—Ç–µ–º.

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã?

> Retriever (–ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤) + Reader (—á—Ç–µ–Ω–∏–µ –∏ –æ—Ç–≤–µ—Ç) + Generator (LLM).

---
## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞

| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç                 | –ö–ª–∞—Å—Å         | –û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ         |
| -------------------------- | ------------- | --------------------------- |
| **Kubernetes**             | Orchestration | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏     |
| **Helm**                   | Packaging     | –®–∞–±–ª–æ–Ω—ã –∏ –¥–µ–ø–ª–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π |
| **ArgoCD / Flux**          | GitOps        | –ê–≤—Ç–æ–¥–µ–ø–ª–æ–π –∏–∑ Git           |
| **Harbor**                 | Registry      | –•—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤ –∏ —á–∞—Ä—Ç–æ–≤   |
| **Superset**               | BI            | –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è    |
| **vLLM / SGLang / Triton** | Inference     | –ë—ã—Å—Ç—Ä—ã–π LLM-—Å–µ—Ä–≤–µ—Ä          |
| **LangChain**              | App Logic     | –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π   |
| **LlamaIndex / Haystack**  | Data Layer    | RAG –∏ –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º   |

---

### vLLM vs HuggingFace Transformers ‚Äî –∑–∞—á–µ–º vLLM?

> Transformers –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è,
> vLLM ‚Äî –¥–ª—è **serving** (–≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –≤—ã–¥–∞—á–∞).
> –û–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç GPU –ø–∞–º—è—Ç—å –∏ —É–º–µ–µ—Ç —Å—Ç—Ä–∏–º–∏—Ç—å —Ç–æ–∫–µ–Ω—ã —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π.

---

### –ß—Ç–æ —Ç–∞–∫–æ–µ PagedAttention?

> –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–Ω–∏–º–∞–Ω–∏—è (Attention), –≥–¥–µ –∫–ª—é—á–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ ‚Äú—Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö‚Äù –ø–∞–º—è—Ç–∏.
> –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å–µ—Ä–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –±–µ–∑ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è GPU.

---

### vLLM vs SGLang?

| –ü–∞—Ä–∞–º–µ—Ç—Ä           | vLLM              | SGLang                  |
| ------------------ | ----------------- | ----------------------- |
| –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è        | PagedAttention    | Graph Execution         |
| –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | –°—Ç–∞–±–∏–ª—å–Ω–æ –≤—ã—Å–æ–∫–∞—è | –õ—É—á—à–µ –Ω–∞ Multi-GPU      |
| –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å      | OpenAI API        | OpenAI API              |
| –°–ª–æ–∂–Ω–æ—Å—Ç—å          | –ü—Ä–æ—Å—Ç–∞—è           | –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ |

---

### Triton vs vLLM ‚Äî –∑–∞—á–µ–º –æ–±–∞?

> Triton ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π inference —Å–µ—Ä–≤–µ—Ä (PyTorch, TF, ONNX).
> vLLM ‚Äî —É–∑–∫–æ—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ LLM.
> –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å vLLM –≤–Ω—É—Ç—Ä–∏ Triton –∫–∞–∫ backend.

---

### LangChain vs LlamaIndex ‚Äî –≤ —á—ë–º —Ä–∞–∑–Ω–∏—Ü–∞?

> LangChain ‚Äî –ø—Ä–æ **–ª–æ–≥–∏—á–µ—Å–∫—É—é —Ü–µ–ø–æ—á–∫—É** (–∞–≥–µ–Ω—Ç—ã, memory, tools).
> LlamaIndex ‚Äî –ø—Ä–æ **–¥–∞–Ω–Ω—ã–µ** (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–Ω–µ—à–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, RAG).
> –ß–∞—Å—Ç–æ –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ: LlamaIndex –ø–æ–¥–∞—ë—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ LangChain.

---

### Haystack vs LangChain?

> Haystack ‚Äî –±–æ–ª—å—à–µ ‚Äú–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π‚Äù —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏ –∏ REST API.
> LangChain ‚Äî –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏ –ª–æ–≥–∏–∫–∏.
> –î–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞: Haystack, –¥–ª—è –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤: LangChain.

---

### –ß—Ç–æ —Ç–∞–∫–æ–µ RAG?

> **Retrieval-Augmented Generation** ‚Äî LLM –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã,
> –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (retrieval + generation).

---

### –ü–æ—á–µ–º—É Triton –ø–æ–ø—É–ª—è—Ä–µ–Ω –≤ –ø—Ä–æ–¥–∞–∫—à–Ω–µ?

> –û–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **batching, metrics, scaling**, –∏ –ª–µ–≥–∫–æ –≤—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤ MLops –ø–∞–π–ø–ª–∞–π–Ω—ã.
> –ú–æ–∂–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –¥–µ—Å—è—Ç–∫–∏ –º–æ–¥–µ–ª–µ–π —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤.


### –ö–∞–∫ —É–º–µ–Ω—å—à–∏—Ç—å –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ LLM inference?

> –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **vLLM —Å preloading**, **TensorRT-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é**,
> **lazy load** –∏ **warmup requests** –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.

---

###  –ß—Ç–æ –¥–µ–ª–∞–µ—Ç vLLM?

> –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä inference –¥–ª—è LLM, —ç–∫–æ–Ω–æ–º–∏—Ç GPU –ø–∞–º—è—Ç—å (PagedAttention).

---

###  –ß—Ç–æ —Ç–∞–∫–æ–µ PagedAttention?

> –ú–µ—Ö–∞–Ω–∏–∑–º –ø–∞–º—è—Ç–∏ –≤ vLLM, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è KV-–∫—ç—à–∞.

---

### Triton Inference Server ‚Äî –∑–∞—á–µ–º –Ω—É–∂–µ–Ω?

> Production-—Å–µ—Ä–≤–µ—Ä –æ—Ç NVIDIA –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–µ–π (PyTorch, TF, ONNX) —Å GPU-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.

---

### LangChain ‚Äî –∫–ª—é—á–µ–≤–∞—è –∏–¥–µ—è?

> –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π: –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏, memory, –∞–≥–µ–Ω—Ç—ã –∏ –≤–Ω–µ—à–Ω–∏–µ API –≤ —Ü–µ–ø–æ—á–∫–∏.

---

### LlamaIndex ‚Äî –∑–∞—á–µ–º –Ω—É–∂–µ–Ω?

> –°–≤—è–∑—ã–≤–∞–µ—Ç LLM —Å –≤–Ω–µ—à–Ω–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ (Retrieval-Augmented Generation, RAG).

---

### Haystack ‚Äî —á–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è?

> –ë–æ–ª–µ–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ RAG, —Å REST API –∏ –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏ (Retriever, Reader, Generator).